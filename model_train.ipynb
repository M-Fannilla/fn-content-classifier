{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7b941b7c2f9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0172ef8601fc1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmiloszbertman\u001B[0m to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "# Login to wandb\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d130ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "CUDA Version: None\n",
      "PyTorch Version: 2.9.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Import our custom modules\n",
    "from config import Config\n",
    "from dataset import create_data_loaders\n",
    "from metrics import plot_roc_curves, plot_precision_recall_curves\n",
    "from model import create_model, setup_model_for_training, count_parameters\n",
    "from trainer import Trainer\n",
    "\n",
    "\n",
    "def set_seed(seed: int) -> None:\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create configuration object\n",
    "config = Config()\n",
    "config.info()"
   ],
   "id": "edd720e675ef6f89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Enable wandb logging\n",
    "config.use_wandb = True\n",
    "config.wandb_tags = ['multilabel', 'convnextv2', 'finetuning']\n",
    "config.wandb_config()"
   ],
   "id": "2ec9a41295490de4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Updated Dataset Loading with Label Distribution Data\n",
    "# ===================================================\n",
    "\n",
    "print(\"Loading and preparing dataset with distribution data...\")\n",
    "\n",
    "# Create data loaders with stratified splitting (updated signature)\n",
    "train_loader, val_loader, label_columns, original_labels, train_labels, test_labels = create_data_loaders(config)\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"  Number of classes: {len(label_columns)}\")\n",
    "print(f\"  Class names: {label_columns}\")\n",
    "print(f\"  Training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_loader.dataset)}\")\n",
    "print(f\"  Training batches: {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "\n",
    "# Display sample batch info\n",
    "sample_batch = next(iter(train_loader))\n",
    "images, labels = sample_batch\n",
    "print(f\"\\nSample batch shape:\")\n",
    "print(f\"  Images: {images.shape}\")\n",
    "print(f\"  Labels: {labels.shape}\")\n",
    "print(f\"  Label range: [{labels.min():.3f}, {labels.max():.3f}]\")\n",
    "print(f\"  Positive labels per sample: {labels.sum(dim=1).float().mean():.2f}\")\n",
    "\n",
    "# Store the label data for later use\n",
    "print(f\"\\nLabel distribution data available:\")\n",
    "print(f\"  Original labels shape: {original_labels.shape}\")\n",
    "print(f\"  Train labels shape: {train_labels.shape}\")\n",
    "print(f\"  Test labels shape: {test_labels.shape}\")\n"
   ],
   "id": "e0ae35d47229eff1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Label Distribution Visualization\n",
    "# ===============================\n",
    "\n",
    "print(\"Creating label distribution visualization...\")\n",
    "\n",
    "# Import the visualization function\n",
    "from dataset import plot_label_distribution\n",
    "\n",
    "# Create the visualization\n",
    "plot_label_distribution(\n",
    "    original_labels=original_labels,\n",
    "    train_labels=train_labels,\n",
    "    test_labels=test_labels,\n",
    "    label_columns=label_columns,\n",
    "    save_path=os.path.join(config.output_dir, 'label_distribution.png')\n",
    ")\n",
    "\n",
    "print(\"Label distribution analysis completed!\")\n"
   ],
   "id": "58a31649f4b58899"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Class Imbalance Analysis and Configuration\n",
    "# ==========================================\n",
    "\n",
    "print(\"Analyzing class imbalance and configuring class weights...\")\n",
    "\n",
    "# Show current configuration\n",
    "print(f\"\\nClass Weight Configuration:\")\n",
    "print(f\"  Use class weights: {config.use_class_weights}\")\n",
    "print(f\"  Class weight method: {config.class_weight_method}\")\n",
    "print(f\"  Loss function: {config.loss_type}\")\n",
    "\n",
    "# Calculate and display class weights if enabled\n",
    "if config.use_class_weights:\n",
    "    from losses import print_class_weights\n",
    "\n",
    "    # Get training labels\n",
    "    train_labels = train_loader.dataset.labels\n",
    "\n",
    "    # Print class weights analysis\n",
    "    class_weights = print_class_weights(\n",
    "        train_labels,\n",
    "        label_columns,\n",
    "        method=config.class_weight_method\n",
    "    )\n",
    "\n",
    "    # Store class weights for later use\n",
    "    config.class_weights = class_weights\n",
    "\n",
    "    print(f\"\\nClass weights calculated and stored in config.class_weights\")\n",
    "    print(f\"Class weights shape: {class_weights.shape}\")\n",
    "    print(f\"Class weights device: {class_weights.device if hasattr(class_weights, 'device') else 'CPU'}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nClass weights are disabled. Set config.use_class_weights = True to enable.\")\n",
    "    print(\"Available class weight methods:\")\n",
    "    print(\"  - 'inverse_freq': Inverse frequency weighting (default)\")\n",
    "    print(\"  - 'balanced': Balanced weighting (sklearn style)\")\n",
    "    print(\"  - 'sqrt_inverse_freq': Square root of inverse frequency\")\n",
    "\n",
    "print(f\"\\nAvailable loss functions:\")\n",
    "print(\"  - 'focal': Focal Loss (good for class imbalance)\")\n",
    "print(\"  - 'asymmetric': Asymmetric Loss\")\n",
    "print(\"  - 'weighted_bce': Weighted Binary Cross Entropy\")\n",
    "print(\"  - 'bce': Standard Binary Cross Entropy\")\n"
   ],
   "id": "3f912c83eecfc126"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Model Creation and Setup\n",
    "# =========================\n",
    "\n",
    "print(\"Creating and setting up model...\")\n",
    "\n",
    "# Create model\n",
    "model = create_model(\n",
    "    config=config,\n",
    "    num_classes=len(label_columns)\n",
    ")\n",
    "\n",
    "# Setup model for training (freeze/unfreeze based on training mode)\n",
    "model = setup_model_for_training(\n",
    "    model=model,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "param_counts = count_parameters(model)\n",
    "print(f\"Model created successfully!\")\n",
    "print(f\"  Total parameters: {param_counts['total']:,}\")\n",
    "print(f\"  Trainable parameters: {param_counts['trainable']:,}\")\n",
    "print(f\"  Frozen parameters: {param_counts['frozen']:,}\")\n",
    "print(f\"  Training mode: Finetuning (backbone frozen, classifier trainable)\")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "print(f\"  Model moved to: {device}\")\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\nTesting forward pass...\")\n",
    "with torch.no_grad():\n",
    "    sample_images = torch.randn(2, 3, config.img_size, config.img_size).to(device)\n",
    "    sample_output = model(sample_images)\n",
    "    print(f\"  Input shape: {sample_images.shape}\")\n",
    "    print(f\"  Output shape: {sample_output.shape}\")\n",
    "    print(f\"  Output range: [{sample_output.min():.3f}, {sample_output.max():.3f}]\")\n",
    "\n",
    "# Show class weight configuration\n",
    "print(f\"\\nClass Weight Configuration:\")\n",
    "print(f\"  Use class weights: {config.use_class_weights}\")\n",
    "print(f\"  Class weight method: {config.class_weight_method}\")\n",
    "print(f\"  Loss function: {config.loss_type}\")\n",
    "if hasattr(config, 'class_weights') and config.class_weights is not None:\n",
    "    print(f\"  Class weights calculated: Yes\")\n",
    "    print(f\"  Class weights shape: {config.class_weights.shape}\")\n",
    "else:\n",
    "    print(f\"  Class weights calculated: No\")\n"
   ],
   "id": "b5dfcd43eba9249c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Training Setup\n",
    "# ==============\n",
    "\n",
    "print(\"Setting up trainer...\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    config=config,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    label_columns=label_columns,\n",
    "    device=str(device)\n",
    ")\n",
    "\n",
    "print(\"Trainer setup complete!\")\n",
    "print(f\"  Loss function: {config.loss_type}\")\n",
    "print(f\"  Class weights: {'Enabled' if config.use_class_weights else 'Disabled'}\")\n",
    "if config.use_class_weights:\n",
    "    print(f\"  Class weight method: {config.class_weight_method}\")\n",
    "print(f\"  Optimizer: AdamW (lr={config.learning_rate})\")\n",
    "print(f\"  Scheduler: ReduceLROnPlateau (patience={config.lr_reduce_patience})\")\n",
    "print(f\"  Early stopping: Enabled (patience={config.early_stopping_patience})\")\n",
    "print(f\"  Mixed precision: Enabled\")\n",
    "print(f\"  Threshold: {config.threshold}\")\n",
    "print(f\"  Training mode: Finetuning\")\n"
   ],
   "id": "fff091168631567d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Training Execution\n",
    "# ==================\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Start training\n",
    "history = trainer.train()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best validation F1 Micro: {trainer.best_val_f1:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "print(\"\\nPlotting training history...\")\n",
    "trainer.plot_training_history(save_path=os.path.join(config.output_dir, 'training_history.png'))\n"
   ],
   "id": "41e021d159954c25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Model Evaluation and Analysis\n",
    "# =============================\n",
    "\n",
    "print(\"Evaluating model on validation set...\")\n",
    "\n",
    "# Get final validation metrics\n",
    "val_loss, val_metrics = trainer.validate_epoch()\n",
    "\n",
    "print(\"\\nFinal Validation Metrics:\")\n",
    "print(f\"  Loss: {val_loss:.4f}\")\n",
    "print(f\"  F1 Micro: {val_metrics['f1_micro']:.4f}\")\n",
    "print(f\"  F1 Macro: {val_metrics['f1_macro']:.4f}\")\n",
    "print(f\"  F1 Samples: {val_metrics['f1_samples']:.4f}\")\n",
    "print(f\"  Precision Micro: {val_metrics['precision_micro']:.4f}\")\n",
    "print(f\"  Precision Macro: {val_metrics['precision_macro']:.4f}\")\n",
    "print(f\"  Recall Micro: {val_metrics['recall_micro']:.4f}\")\n",
    "print(f\"  Recall Macro: {val_metrics['recall_macro']:.4f}\")\n",
    "\n",
    "if 'roc_auc_micro' in val_metrics:\n",
    "    print(f\"  ROC AUC Micro: {val_metrics['roc_auc_micro']:.4f}\")\n",
    "    print(f\"  ROC AUC Macro: {val_metrics['roc_auc_macro']:.4f}\")\n",
    "    print(f\"  PR AUC Micro: {val_metrics['pr_auc_micro']:.4f}\")\n",
    "    print(f\"  PR AUC Macro: {val_metrics['pr_auc_macro']:.4f}\")\n",
    "\n",
    "# Get per-class metrics\n",
    "print(\"\\nComputing per-class metrics...\")\n",
    "per_class_metrics = trainer.metrics_calculator.compute_per_class_metrics(\n",
    "    y_true=val_loader.dataset.labels,\n",
    "    y_pred=np.concatenate([trainer.model(torch.tensor(batch[0]).to(device)).cpu().detach().numpy()\n",
    "                           for batch in val_loader]),\n",
    "    class_names=label_columns\n",
    ")\n",
    "\n",
    "print(\"\\nPer-class F1 Scores:\")\n",
    "for class_name, metrics in per_class_metrics.items():\n",
    "    print(f\"  {class_name}: {metrics['f1']:.4f} (support: {metrics['support']})\")\n"
   ],
   "id": "7725f26f567f8039"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualization and Analysis\n",
    "# ===========================\n",
    "\n",
    "print(\"Generating visualizations...\")\n",
    "\n",
    "# Get predictions for visualization\n",
    "trainer.model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_probabilities = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = trainer.model(images)\n",
    "        probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
    "        predictions = outputs.cpu().numpy()\n",
    "        labels_np = labels.cpu().numpy()\n",
    "\n",
    "        all_predictions.append(predictions)\n",
    "        all_labels.append(labels_np)\n",
    "        all_probabilities.append(probabilities)\n",
    "\n",
    "all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "all_probabilities = np.concatenate(all_probabilities, axis=0)\n",
    "\n",
    "# Plot ROC curves\n",
    "print(\"Plotting ROC curves...\")\n",
    "plot_roc_curves(\n",
    "    all_labels,\n",
    "    all_probabilities,\n",
    "    label_columns,\n",
    "    save_path=os.path.join(config.output_dir, 'roc_curves.png')\n",
    ")\n",
    "\n",
    "# Plot Precision-Recall curves\n",
    "print(\"Plotting Precision-Recall curves...\")\n",
    "plot_precision_recall_curves(\n",
    "    all_labels,\n",
    "    all_probabilities,\n",
    "    label_columns,\n",
    "    save_path=os.path.join(config.output_dir, 'pr_curves.png')\n",
    ")\n"
   ],
   "id": "aefa50c464cd29bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc0456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Saving\n",
    "# ============\n",
    "\n",
    "print(\"Saving model and results...\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(config.output_dir, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(config.output_dir, f'{config.model_name}_finetuned_best.pth')\n",
    "trainer.save_model(model_path)\n",
    "\n",
    "# Save training history as CSV\n",
    "history_df = pd.DataFrame(history)\n",
    "history_path = os.path.join(config.output_dir, 'training_history.csv')\n",
    "history_df.to_csv(history_path, index=False)\n",
    "print(f\"Training history saved to: {history_path}\")\n",
    "\n",
    "# Save configuration\n",
    "config_path = os.path.join(config.output_dir, 'config.json')\n",
    "import json\n",
    "\n",
    "with open(config_path, 'w') as f:\n",
    "    config_dict = {\n",
    "        'model_name': config.model_name,\n",
    "        'training_mode': 'finetuning',\n",
    "        'learning_rate': config.learning_rate,\n",
    "        'epochs': config.epochs,\n",
    "        'batch_size': config.batch_size,\n",
    "        'img_size': config.img_size,\n",
    "        'threshold': config.threshold,\n",
    "        'label_columns': label_columns,\n",
    "        'best_val_f1': trainer.best_val_f1\n",
    "    }\n",
    "    json.dump(config_dict, f, indent=2)\n",
    "print(f\"Configuration saved to: {config_path}\")\n",
    "\n",
    "print(f\"\\nAll files saved to: {config.output_dir}\")\n",
    "print(\"Training completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
