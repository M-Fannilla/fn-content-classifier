{
 "cells": [
  {
   "cell_type": "code",
   "id": "ec7b941b7c2f9235",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "720706e039d93c15",
   "metadata": {},
   "source": [
    "# Login to wandb\n",
    "# !wandb login 1d46416e290617f0005c9b98c3592a0350c5fa01"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9d130ed3",
   "metadata": {},
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Import our custom modules\n",
    "from config import Config\n",
    "from dataset import create_data_loaders\n",
    "from metrics import plot_roc_curves, plot_precision_recall_curves\n",
    "from model import create_model, setup_model_for_training\n",
    "from trainer import Trainer\n",
    "from utils import compute_class_frequency\n",
    "from dataset import load_and_prepare_data\n",
    "\n",
    "\n",
    "def set_seed(seed: int) -> None:\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "edd720e675ef6f89",
   "metadata": {},
   "source": [
    "# Create configuration object\n",
    "config = Config()\n",
    "config.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2ec9a41295490de4",
   "metadata": {},
   "source": [
    "# Enable wandb logging\n",
    "config.use_wandb = False\n",
    "config.wandb_tags = [config.model_name]\n",
    "config.wandb_config()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f570e69ea33a01df",
   "metadata": {},
   "source": [
    "## Updated Dataset Loading with Label Distribution Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "3cd41e8759067f55",
   "metadata": {},
   "source": [
    "print(\"Loading and preparing dataset with distribution data...\")\n",
    "\n",
    "# Create data loaders with stratified splitting (updated signature)\n",
    "df, image_paths, labels = load_and_prepare_data(config=config)\n",
    "class_frequency = compute_class_frequency(df.drop(['file_name'], axis=1))\n",
    "train_loader, val_loader, label_columns, original_labels, train_labels, test_labels = create_data_loaders(df, image_paths, labels, config)\n",
    "\n",
    "# Store the label data for later use\n",
    "print(f\"\\nLabel distribution data available:\")\n",
    "print(f\"  Original labels shape: {original_labels.shape}\")\n",
    "print(f\"  Train labels shape: {train_labels.shape}\")\n",
    "print(f\"  Test labels shape: {test_labels.shape}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "94cce6e37f224c1d",
   "metadata": {},
   "source": [
    "## Label Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "id": "549c0580ee197603",
   "metadata": {},
   "source": [
    "print(\"Creating label distribution visualization...\")\n",
    "\n",
    "# Import the visualization function\n",
    "from dataset import plot_label_distribution\n",
    "\n",
    "# Create the visualization\n",
    "plot_label_distribution(\n",
    "    original_labels=original_labels,\n",
    "    train_labels=train_labels,\n",
    "    test_labels=test_labels,\n",
    "    label_columns=label_columns,\n",
    ")\n",
    "\n",
    "print(\"Label distribution analysis completed!\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "286572b19c99a7dd",
   "metadata": {},
   "source": [
    "## Class Imbalance Analysis and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "id": "77555bde44f71500",
   "metadata": {},
   "source": [
    "print(\"Analyzing class imbalance and configuring class weights...\")\n",
    "\n",
    "# Show current configuration\n",
    "print(f\"\\nClass Weight Configuration:\")\n",
    "print(f\"  Class weight method: {config.class_weight_method}\")\n",
    "print(f\"  Loss function: {config.loss_type}\")\n",
    "\n",
    "# Calculate and display class weights if enabled\n",
    "if config.class_weight_method != 'none':\n",
    "    from losses import print_class_weights\n",
    "\n",
    "    # Get training labels\n",
    "    train_labels = train_loader.dataset.labels\n",
    "\n",
    "    # Print class weights analysis\n",
    "    class_weights = print_class_weights(\n",
    "        train_labels,\n",
    "        label_columns,\n",
    "        method=config.class_weight_method\n",
    "    )\n",
    "\n",
    "    # Store class weights for later use\n",
    "    config.class_weights = class_weights\n",
    "\n",
    "    print(f\"\\nClass weights calculated and stored in config.class_weights\")\n",
    "    print(f\"Class weights shape: {class_weights.shape}\")\n",
    "    print(f\"Class weights device: {class_weights.device}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1d6c81be5aad3cf4",
   "metadata": {},
   "source": [
    "## Model Creation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "ef0de2577e6e6e2",
   "metadata": {},
   "source": [
    "print(\"Creating and setting up model...\")\n",
    "\n",
    "# Create model\n",
    "model = create_model(config=config, num_classes=len(label_columns))\n",
    "\n",
    "# Setup model for training (freeze/unfreeze based on training mode)\n",
    "model = setup_model_for_training(model=model, device=device, config=config)\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\nTesting forward pass...\")\n",
    "with torch.no_grad():\n",
    "    sample_images = torch.randn(2, 3, config.img_size, config.img_size).to(device)\n",
    "    sample_output = model(sample_images)\n",
    "    print(f\"  Input shape: {sample_images.shape}\")\n",
    "    print(f\"  Output shape: {sample_output.shape}\")\n",
    "    print(f\"  Output range: [{sample_output.min():.3f}, {sample_output.max():.3f}]\")\n",
    "\n",
    "# Show class weight configuration\n",
    "print(f\"\\nClass Weight Configuration:\")\n",
    "print(f\"  Class weight method: {config.class_weight_method}\")\n",
    "print(f\"  Loss function: {config.loss_type}\")\n",
    "\n",
    "if config.class_weights != 'none':\n",
    "    print(f\"  Class weights calculated: Yes\")\n",
    "    print(f\"  Class weights shape: {config.class_weights.shape}\")\n",
    "else:\n",
    "    print(f\"  Class weights calculated: No\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "495b69ca9141abea",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "aa553a44f87708e6",
   "metadata": {},
   "source": [
    "print(\"Setting up trainer...\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    class_freq=class_frequency,\n",
    "    config=config,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    label_columns=label_columns,\n",
    "    device=str(device),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8689e6b2753c4ad9",
   "metadata": {},
   "source": [
    "## Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "id": "b62ee4ffcfb01f3e",
   "metadata": {},
   "source": [
    "print(\"Starting training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Start training\n",
    "history = trainer.train()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best validation F1 Micro: {trainer.best_val_f1:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "print(\"\\nPlotting training history...\")\n",
    "trainer.plot_training_history(save_path=os.path.join(config.output_dir, 'training_history.png'))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "56d844c23cc0b178",
   "metadata": {},
   "source": [
    "# Model Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "7725f26f567f8039",
   "metadata": {},
   "source": [
    "val_loss, val_metrics = trainer.validate_epoch()\n",
    "\n",
    "print(\"\\nFinal Validation Metrics:\")\n",
    "print(f\"  Loss: {val_loss:.4f}\")\n",
    "print(f\"  F1 Micro: {val_metrics['f1_micro']:.4f}\")\n",
    "print(f\"  F1 Macro: {val_metrics['f1_macro']:.4f}\")\n",
    "print(f\"  F1 Samples: {val_metrics['f1_samples']:.4f}\")\n",
    "print(f\"  Precision Micro: {val_metrics['precision_micro']:.4f}\")\n",
    "print(f\"  Precision Macro: {val_metrics['precision_macro']:.4f}\")\n",
    "print(f\"  Recall Micro: {val_metrics['recall_micro']:.4f}\")\n",
    "print(f\"  Recall Macro: {val_metrics['recall_macro']:.4f}\")\n",
    "\n",
    "if 'roc_auc_micro' in val_metrics:\n",
    "    print(f\"  ROC AUC Micro: {val_metrics['roc_auc_micro']:.4f}\")\n",
    "    print(f\"  ROC AUC Macro: {val_metrics['roc_auc_macro']:.4f}\")\n",
    "    print(f\"  PR AUC Micro: {val_metrics['pr_auc_micro']:.4f}\")\n",
    "    print(f\"  PR AUC Macro: {val_metrics['pr_auc_macro']:.4f}\")\n",
    "\n",
    "# Get per-class metrics\n",
    "print(\"\\nComputing per-class metrics...\")\n",
    "per_class_metrics = trainer.metrics_calculator.compute_per_class_metrics(\n",
    "    y_true=val_loader.dataset.labels,\n",
    "    y_pred=np.concatenate([trainer.model(torch.tensor(batch[0]).to(device)).cpu().detach().numpy()\n",
    "                           for batch in val_loader]),\n",
    "    class_names=label_columns\n",
    ")\n",
    "\n",
    "print(\"\\nPer-class F1 Scores:\")\n",
    "for class_name, metrics in per_class_metrics.items():\n",
    "    print(f\"  {class_name}: {metrics['f1']:.4f} (support: {metrics['support']})\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "64d0438ba8f15a88",
   "metadata": {},
   "source": [
    "## Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "aefa50c464cd29bc",
   "metadata": {},
   "source": [
    "print(\"Generating visualizations...\")\n",
    "\n",
    "# Get predictions for visualization\n",
    "trainer.model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_probabilities = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = trainer.model(images)\n",
    "        probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
    "        predictions = outputs.cpu().numpy()\n",
    "        labels_np = labels.cpu().numpy()\n",
    "\n",
    "        all_predictions.append(predictions)\n",
    "        all_labels.append(labels_np)\n",
    "        all_probabilities.append(probabilities)\n",
    "\n",
    "all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "all_probabilities = np.concatenate(all_probabilities, axis=0)\n",
    "\n",
    "# Plot ROC curves\n",
    "print(\"Plotting ROC curves...\")\n",
    "plot_roc_curves(\n",
    "    all_labels,\n",
    "    all_probabilities,\n",
    "    label_columns,\n",
    "    save_path=os.path.join(config.output_dir, 'roc_curves.png')\n",
    ")\n",
    "\n",
    "# Plot Precision-Recall curves\n",
    "print(\"Plotting Precision-Recall curves...\")\n",
    "plot_precision_recall_curves(\n",
    "    all_labels,\n",
    "    all_probabilities,\n",
    "    label_columns,\n",
    "    save_path=os.path.join(config.output_dir, 'pr_curves.png')\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e5d047fe702af6b5",
   "metadata": {},
   "source": [
    "from utils import visualize_predictions\n",
    "\n",
    "SAMPLES = 5\n",
    "dataset = iter(val_loader.dataset)\n",
    "\n",
    "images, labels = [], []\n",
    "for s in range(SAMPLES):\n",
    "    img, label = next(dataset)\n",
    "    images.append(img)\n",
    "    labels.append(label)\n",
    "\n",
    "test_images = torch.stack(images, dim=0)\n",
    "test_labels = torch.stack(labels, dim=0)\n",
    "\n",
    "visualize_predictions(\n",
    "    model=trainer.model,\n",
    "    test_images=test_images,\n",
    "    test_labels=test_labels,\n",
    "    label_columns=label_columns,\n",
    "    threshold=config.threshold,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c8382fead8106481",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
