{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0686427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting with Class Weight Configurations\n",
    "# ===============================================\n",
    "\n",
    "print(\"Class Weight Experimentation Options:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n1. To enable/disable class weights:\")\n",
    "print(\"   config.use_class_weights = True   # Enable class weights\")\n",
    "print(\"   config.use_class_weights = False  # Disable class weights\")\n",
    "\n",
    "print(\"\\n2. To change class weight calculation method:\")\n",
    "print(\"   config.class_weight_method = 'inverse_freq'      # Default\")\n",
    "print(\"   config.class_weight_method = 'balanced'          # Sklearn style\")\n",
    "print(\"   config.class_weight_method = 'sqrt_inverse_freq' # Square root\")\n",
    "\n",
    "print(\"\\n3. To change loss function:\")\n",
    "print(\"   config.loss_type = 'focal'        # Focal Loss (recommended for imbalance)\")\n",
    "print(\"   config.loss_type = 'weighted_bce' # Weighted BCE (uses class weights)\")\n",
    "print(\"   config.loss_type = 'asymmetric'   # Asymmetric Loss\")\n",
    "print(\"   config.loss_type = 'bce'          # Standard BCE\")\n",
    "\n",
    "print(\"\\n4. Example configurations for different scenarios:\")\n",
    "print(\"   # For severe class imbalance:\")\n",
    "print(\"   config.use_class_weights = True\")\n",
    "print(\"   config.class_weight_method = 'balanced'\")\n",
    "print(\"   config.loss_type = 'focal'\")\n",
    "print(\"\")\n",
    "print(\"   # For moderate imbalance with weighted BCE:\")\n",
    "print(\"   config.use_class_weights = True\")\n",
    "print(\"   config.class_weight_method = 'inverse_freq'\")\n",
    "print(\"   config.loss_type = 'weighted_bce'\")\n",
    "print(\"\")\n",
    "print(\"   # For no class weighting:\")\n",
    "print(\"   config.use_class_weights = False\")\n",
    "print(\"   config.loss_type = 'focal'  # Still use focal loss for imbalance\")\n",
    "\n",
    "print(\"\\n5. Current configuration:\")\n",
    "print(f\"   use_class_weights: {config.use_class_weights}\")\n",
    "print(f\"   class_weight_method: {config.class_weight_method}\")\n",
    "print(f\"   loss_type: {config.loss_type}\")\n",
    "\n",
    "print(\"\\nNote: Class weights are calculated from training data and applied during training.\")\n",
    "print(\"The weights help the model focus more on underrepresented classes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping and Learning Rate Reduction\n",
    "# ===========================================\n",
    "\n",
    "print(\"Training Features:\")\n",
    "print(\"\\n1. Early Stopping:\")\n",
    "print(f\"   - Patience: {config.early_stopping_patience} epochs\")\n",
    "print(f\"   - Min Delta: {config.early_stopping_min_delta}\")\n",
    "print(\"   - Monitors: Validation F1 Micro score\")\n",
    "print(\"   - Stops training when no improvement for patience epochs\")\n",
    "\n",
    "print(\"\\n2. Learning Rate Reduction on Plateau:\")\n",
    "print(f\"   - Patience: {config.lr_reduce_patience} epochs\")\n",
    "print(f\"   - Factor: {config.lr_reduce_factor} (reduces LR by this factor)\")\n",
    "print(f\"   - Min LR: {config.lr_reduce_min_lr}\")\n",
    "print(\"   - Monitors: Validation F1 Micro score\")\n",
    "print(\"   - Reduces LR when no improvement for patience epochs\")\n",
    "\n",
    "print(\"\\n3. Benefits:\")\n",
    "print(\"   - Prevents overfitting with early stopping\")\n",
    "print(\"   - Automatically adjusts learning rate for better convergence\")\n",
    "print(\"   - Saves training time by stopping when no improvement\")\n",
    "print(\"   - Always loads the best model at the end\")\n",
    "\n",
    "print(\"\\n4. Monitoring:\")\n",
    "print(\"   - Watch for 'New best F1 Micro' messages\")\n",
    "print(\"   - Watch for 'Reducing learning rate' messages\")\n",
    "print(\"   - Training will stop early if no improvement\")\n",
    "print(\"   - Best model is automatically loaded at the end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights & Biases Hyperparameter Sweep\n",
    "# =====================================\n",
    "\n",
    "print(\"Wandb Sweep Options:\")\n",
    "print(\"\\n1. Manual Sweep (Run this notebook multiple times with different configs)\")\n",
    "print(\"   - Modify the config parameters in cell 2\")\n",
    "print(\"   - Run all cells to train with new parameters\")\n",
    "print(\"   - Compare results in wandb dashboard\")\n",
    "\n",
    "print(\"\\n2. Automated Sweep (Recommended)\")\n",
    "print(\"   - Run: python run_sweep.py\")\n",
    "print(\"   - This will automatically test different hyperparameter combinations\")\n",
    "print(\"   - Uses Bayesian optimization to find best parameters\")\n",
    "\n",
    "print(\"\\n3. Sweep Configuration:\")\n",
    "print(\"   - Model: convnextv2_nano, convnextv2_tiny, convnextv2_base\")\n",
    "print(\"   - Learning Rate: 1e-6 to 1e-3 (log scale)\")\n",
    "print(\"   - Batch Size: 16, 32, 64\")\n",
    "print(\"   - Image Size: 224, 256, 384\")\n",
    "print(\"   - Threshold: 0.3, 0.4, 0.5, 0.6, 0.7\")\n",
    "print(\"   - Early Stopping Patience: 5, 10, 15\")\n",
    "print(\"   - LR Reduce Patience: 3, 5, 7\")\n",
    "print(\"   - LR Reduce Factor: 0.3, 0.5, 0.7\")\n",
    "\n",
    "print(\"\\n4. Key Metrics Tracked:\")\n",
    "print(\"   - val_f1_micro (primary metric for optimization)\")\n",
    "print(\"   - val_f1_macro, val_f1_samples\")\n",
    "print(\"   - val_precision_micro, val_precision_macro\")\n",
    "print(\"   - val_recall_micro, val_recall_macro\")\n",
    "print(\"   - val_roc_auc_micro, val_roc_auc_macro\")\n",
    "print(\"   - val_pr_auc_micro, val_pr_auc_macro\")\n",
    "print(\"   - train_loss, val_loss\")\n",
    "print(\"   - learning_rate, best_val_f1\")\n",
    "\n",
    "print(\"\\n5. To start a sweep:\")\n",
    "print(\"   !python run_sweep.py\")\n",
    "print(\"   # Or run the sweep configuration directly:\")\n",
    "print(\"   !wandb sweep wandb_sweep_config.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf1e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison and Experimentation\n",
    "# ====================================\n",
    "\n",
    "print(\"Model comparison and experimentation options:\")\n",
    "print(\"\\n1. Try different ConvNeXt V2 variants:\")\n",
    "print(\"   - convnextv2_nano: Fastest, smallest\")\n",
    "print(\"   - convnextv2_tiny: Good balance (current)\")\n",
    "print(\"   - convnextv2_base: Better accuracy\")\n",
    "print(\"   - convnextv2_large: High accuracy\")\n",
    "print(\"   - convnextv2_huge: Best accuracy, slowest\")\n",
    "\n",
    "print(\"\\n2. Finetuning benefits:\")\n",
    "print(\"   - Fast training (only classifier head is trained)\")\n",
    "print(\"   - Good for small to medium datasets\")\n",
    "print(\"   - Preserves pretrained features\")\n",
    "\n",
    "print(\"\\n3. Try different loss functions:\")\n",
    "print(\"   - Focal Loss: Good for class imbalance (current)\")\n",
    "print(\"   - Asymmetric Loss: Alternative for imbalance\")\n",
    "print(\"   - Weighted BCE: Simple weighted approach\")\n",
    "\n",
    "print(\"\\n4. Hyperparameter tuning suggestions:\")\n",
    "print(\"   - Learning rate: 1e-5 to 1e-3\")\n",
    "print(\"   - Batch size: 16, 32, 64\")\n",
    "print(\"   - Image size: 224, 256, 384\")\n",
    "print(\"   - Threshold: 0.3 to 0.7\")\n",
    "\n",
    "print(\"\\nTo experiment with different models, modify the config in cell 2:\")\n",
    "print(\"config.model_name = 'convnextv2_base'  # Change model\")\n",
    "print(\"config.epochs = 30  # Change epochs\")\n",
    "print(\"config.learning_rate = 2e-5  # Change learning rate\")\n",
    "\n",
    "print(\"\\nTraining completed! Check the outputs directory for results.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
