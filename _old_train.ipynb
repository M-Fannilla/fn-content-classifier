{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cfb4503-445f-4ba4-9382-943eb14423ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import timm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ->>>> conda activate torch311\n",
    "# --------------------\n",
    "# Configuration\n",
    "# --------------------\n",
    "DATASET_SIZE_PERC = 1\n",
    "TRAIN_SIZE_PERC = 0.8\n",
    "TEST_SIZE_PERC = 0.2\n",
    "\n",
    "DATASET_SRC = './compiled/compiled'\n",
    "LABEL_DATAFRAME = './compiled/compiled/action_labels.csv'\n",
    "OUTPUT_DIR = './outputs'\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 2e-4\n",
    "# Windows compatibility: use 0 workers to avoid shared memory issues\n",
    "NUM_WORKERS = 0 if os.name == 'nt' else os.cpu_count() // 4\n",
    "THRESHOLD = 0.5\n",
    "IMG_SIZE = 224\n",
    "MODEL_NAME = 'convnextv2_base'  # default smaller, can be overridden\n",
    "CACHE_DECODED_IMAGES = False  # disabled due to memory constraints with large datasets\n",
    "\n",
    "# Training mode: 'finetune' or 'full_retrain'\n",
    "TRAINING_MODE = 'finetune'  # default to finetuning\n",
    "# Finetuning specific settings\n",
    "FINETUNE_LEARNING_RATE = 1e-5  # lower learning rate for finetuning\n",
    "FINETUNE_EPOCHS = 20  # fewer epochs for finetuning\n",
    "# Full retrain specific settings\n",
    "RETRAIN_LEARNING_RATE = 2e-4  # higher learning rate for full retrain\n",
    "RETRAIN_EPOCHS = 50  # more epochs for full retrain\n",
    "\n",
    "# Catalog of ConvNeXt V2 variants and their recommended input sizes\n",
    "MODEL_CATALOG: Dict[str, int] = {\n",
    "    'convnextv2_nano': IMG_SIZE,\n",
    "    'convnextv2_tiny': IMG_SIZE,\n",
    "    'convnextv2_base': IMG_SIZE,\n",
    "    'convnextv2_large': IMG_SIZE,\n",
    "    'convnextv2_huge': IMG_SIZE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b801efa1-96a4-4df5-877a-ffe08983df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def ensure_output_dir(path: str) -> None:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def load_dataframe(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_filepaths(df: pd.DataFrame, base_dir: str) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if 'file_name' not in df.columns:\n",
    "        raise ValueError(\"Expected 'file_name' column in dataframe\")\n",
    "    df['filepath'] = df['file_name'].apply(lambda x: os.path.join(base_dir, x))\n",
    "    return df\n",
    "\n",
    "\n",
    "def select_subset(df: pd.DataFrame, frac: float, label_cols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Select a stratified subset of the dataset maintaining label distribution.\n",
    "    \n",
    "    Args:\n",
    "        df: Input dataframe\n",
    "        frac: Fraction of data to select (0.0 to 1.0)\n",
    "        label_cols: List of label column names for stratification\n",
    "    \n",
    "    Returns:\n",
    "        Stratified subset of the dataframe\n",
    "    \"\"\"\n",
    "    if frac >= 1.0:\n",
    "        return df\n",
    "    \n",
    "    # Use MultilabelStratifiedKFold to ensure stratified sampling\n",
    "    X = df[['filepath']]  # placeholder features\n",
    "    y = df[label_cols].values\n",
    "    \n",
    "    # Calculate number of splits needed to get approximately the desired fraction\n",
    "    n_splits = max(2, int(1.0 / frac))\n",
    "    \n",
    "    # Use stratified k-fold to get one fold as our subset\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    # Get the first fold as our subset\n",
    "    subset_indices, _ = next(mskf.split(X, y))\n",
    "    \n",
    "    return df.iloc[subset_indices].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def get_label_columns(df: pd.DataFrame) -> List[str]:\n",
    "    non_label_cols = {'file_name', 'filepath'}\n",
    "    return [c for c in df.columns if c not in non_label_cols]\n",
    "\n",
    "\n",
    "def plot_label_distribution(df: pd.DataFrame, label_cols: List[str], out_path: str) -> None:\n",
    "    counts = df[label_cols].sum().sort_values(ascending=False)\n",
    "    plt.figure(figsize=(10, max(4, len(label_cols) * 0.3)))\n",
    "    counts.plot(kind='bar')\n",
    "    plt.title('Label Distribution (counts)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "class MultiLabelImageDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, label_cols: List[str], transform: T.Compose) -> None:\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.label_cols = label_cols\n",
    "        self.transform = transform\n",
    "        self._cache: Dict[str, np.ndarray] = {}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        fp = row['filepath']\n",
    "        if CACHE_DECODED_IMAGES and fp in self._cache:\n",
    "            # cached as numpy array HWC uint8\n",
    "            np_img = self._cache[fp]\n",
    "            image = Image.fromarray(np_img)\n",
    "        else:\n",
    "            image = Image.open(fp).convert('RGB')\n",
    "            if CACHE_DECODED_IMAGES:\n",
    "                self._cache[fp] = np.array(image)\n",
    "        image = self.transform(image)\n",
    "        labels = torch.tensor(row[self.label_cols].values.astype(np.float32))\n",
    "        return image, labels\n",
    "\n",
    "\n",
    "def make_transforms(img_size: int) -> Tuple[T.Compose, T.Compose]:\n",
    "    train_tfms = T.Compose([\n",
    "        T.Resize((img_size, img_size)),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomApply([T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2)], p=0.3),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    val_tfms = T.Compose([\n",
    "        T.Resize((img_size, img_size)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    return train_tfms, val_tfms\n",
    "\n",
    "\n",
    "def multilabel_stratified_split(df: pd.DataFrame, label_cols: List[str],\n",
    "                                train_size: float, test_size: float,\n",
    "                                seed: int) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    assert math.isclose(train_size + test_size, 1.0, rel_tol=1e-6)\n",
    "\n",
    "    X = df[['filepath']]  # placeholder\n",
    "    y = df[label_cols].values\n",
    "\n",
    "    # Split: train vs test\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=int(1 / test_size), shuffle=True, random_state=seed)\n",
    "    train_idx, test_idx = next(mskf.split(X, y))\n",
    "    df_train = df.iloc[train_idx].reset_index(drop=True)\n",
    "    df_test = df.iloc[test_idx].reset_index(drop=True)\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "def compute_pos_weight(df: pd.DataFrame, label_cols: List[str]) -> torch.Tensor:\n",
    "    counts = df[label_cols].sum().values.astype(np.float32)\n",
    "    totals = np.array([len(df)] * len(label_cols), dtype=np.float32)\n",
    "    # pos_weight = (N - P) / P; clamp to avoid div by zero\n",
    "    pos_weight = (totals - counts) / np.clip(counts, 1.0, None)\n",
    "    tw = torch.tensor(pos_weight, dtype=torch.float32)\n",
    "    # Normalize to have mean 1.0 to stabilize loss scaling across runs\n",
    "    mean_val = torch.clamp(tw.mean(), min=1e-6)\n",
    "    tw = tw / mean_val\n",
    "    return tw\n",
    "\n",
    "\n",
    "def build_model(num_classes: int, training_mode: str = 'finetune') -> nn.Module:\n",
    "    try:\n",
    "        if training_mode == 'finetune':\n",
    "            # For finetuning: use pretrained weights and freeze early layers\n",
    "            model = timm.create_model(MODEL_NAME, pretrained=True, in_chans=3, num_classes=num_classes)\n",
    "            \n",
    "            # Freeze early layers for finetuning\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'head' not in name and 'classifier' not in name and 'fc' not in name:\n",
    "                    param.requires_grad = False\n",
    "            \n",
    "            print(f\"Finetuning mode: Frozen {sum(1 for p in model.parameters() if not p.requires_grad)} parameters\")\n",
    "            print(f\"Finetuning mode: Trainable {sum(1 for p in model.parameters() if p.requires_grad)} parameters\")\n",
    "            \n",
    "        elif training_mode == 'full_retrain':\n",
    "            # For full retraining: start from scratch (no pretrained weights)\n",
    "            model = timm.create_model(MODEL_NAME, pretrained=False, in_chans=3, num_classes=num_classes)\n",
    "            print(f\"Full retrain mode: All {sum(1 for p in model.parameters() if p.requires_grad)} parameters are trainable\")\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Invalid training_mode: {training_mode}. Must be 'finetune' or 'full_retrain'\")\n",
    "            \n",
    "        return model\n",
    "    except RuntimeError as e:\n",
    "        available = timm.list_models('convnextv2*')\n",
    "        raise RuntimeError(f\"{e}. Available ConvNeXt V2 models: {available}\") from e\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainResult:\n",
    "    train_losses: List[float]\n",
    "    test_losses: List[float]\n",
    "    test_aurocs: List[float]\n",
    "\n",
    "\n",
    "def sigmoid_np(x: np.ndarray) -> np.ndarray:\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, loader: DataLoader, device: torch.device, threshold: float) -> Tuple[float, float, float]:\n",
    "    model.eval()\n",
    "    all_targets, all_logits = [], []\n",
    "    val_loss = 0.0\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "    with torch.no_grad():\n",
    "        for images, targets in loader:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, targets)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "            all_logits.append(logits.cpu().numpy())\n",
    "\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "    all_logits = np.concatenate(all_logits, axis=0)\n",
    "    all_probs = sigmoid_np(all_logits)\n",
    "\n",
    "    try:\n",
    "        auroc = roc_auc_score(all_targets, all_probs, average='macro')\n",
    "    except Exception:\n",
    "        auroc = float('nan')\n",
    "\n",
    "    try:\n",
    "        mAP = average_precision_score(all_targets, all_probs, average='macro')\n",
    "    except Exception:\n",
    "        mAP = float('nan')\n",
    "\n",
    "    preds = (all_probs >= threshold).astype(np.float32)\n",
    "    acc = (preds == all_targets).mean()\n",
    "\n",
    "    val_loss = val_loss / len(loader.dataset)\n",
    "    return val_loss, auroc, mAP\n",
    "\n",
    "\n",
    "def train(model: nn.Module,\n",
    "          train_loader: DataLoader,\n",
    "          test_loader: DataLoader,\n",
    "          device: torch.device,\n",
    "          pos_weight: torch.Tensor,\n",
    "          epochs: int,\n",
    "          lr: float,\n",
    "          threshold: float,\n",
    "          out_dir: str,\n",
    "          training_mode: str = 'finetune') -> TrainResult:\n",
    "    # Configure optimizer based on training mode\n",
    "    if training_mode == 'finetune':\n",
    "        # For finetuning: only optimize trainable parameters, use lower learning rate\n",
    "        trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer = torch.optim.AdamW(trainable_params, lr=lr, weight_decay=0.01)\n",
    "        print(f\"Finetuning optimizer: {len(trainable_params)} trainable parameters\")\n",
    "    else:\n",
    "        # For full retraining: optimize all parameters\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "        print(f\"Full retrain optimizer: {sum(1 for p in model.parameters())} total parameters\")\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=(device.type == 'cuda'))\n",
    "\n",
    "    best_metric = -float('inf')\n",
    "    history_train_loss, history_test_loss, history_test_auroc = [], [], []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        iterator = tqdm(train_loader, desc=f\"{device.type.upper()}: Epoch {epoch}/{epochs}\", leave=False)\n",
    "\n",
    "        for images, targets in iterator:\n",
    "            images = images.to(device, non_blocking=(device.type == 'cuda'))\n",
    "            targets = targets.to(device, non_blocking=(device.type == 'cuda'))\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n",
    "                logits = model(images)\n",
    "                loss = criterion(logits, targets)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        test_loss, auroc, mAP = evaluate(model, test_loader, device, threshold)\n",
    "\n",
    "        history_train_loss.append(train_loss)\n",
    "        history_test_loss.append(test_loss)\n",
    "        history_test_auroc.append(auroc)\n",
    "\n",
    "        # Save best by AUROC, fallback to mAP if NaN\n",
    "        score = auroc if not math.isnan(auroc) else (mAP if not math.isnan(mAP) else -float('inf'))\n",
    "        if score > best_metric:\n",
    "            best_metric = score\n",
    "            torch.save({'model_state_dict': model.state_dict(),\n",
    "                        'epoch': epoch,\n",
    "                        'test_loss': test_loss,\n",
    "                        'test_auroc': auroc,\n",
    "                        'test_map': mAP}, os.path.join(out_dir, 'best_model.pt'))\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}/{epochs} - train_loss: {train_loss:.4f} test_loss: {test_loss:.4f} AUROC: {auroc:.4f} mAP: {mAP:.4f}\")\n",
    "\n",
    "        # Plot curves each epoch\n",
    "        plot_training_curves(history_train_loss, history_test_loss, history_test_auroc,\n",
    "                             os.path.join(out_dir, 'training_curves.png'))\n",
    "\n",
    "    return TrainResult(history_train_loss, history_test_loss, history_test_auroc)\n",
    "\n",
    "\n",
    "def plot_training_curves(train_losses: List[float], test_losses: List[float], test_aurocs: List[float], out_path: str) -> None:\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "    ax1.plot(epochs, train_losses, label='Train Loss')\n",
    "    ax1.plot(epochs, test_losses, label='Test Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(epochs, test_aurocs, color='green', label='Test AUROC')\n",
    "    ax2.set_ylabel('AUROC')\n",
    "    ax2.legend(loc='lower right')\n",
    "\n",
    "    plt.title('Training Curves')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "\n",
    "def validate_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Validate dataset by checking if image files exist and remove missing ones.\"\"\"\n",
    "    temp_df = df.copy()\n",
    "    missing_indices = []\n",
    "\n",
    "    def _process_file(index: int, filepath: str) -> int:\n",
    "        if not os.path.exists(filepath):\n",
    "            return index\n",
    "        return None\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = []\n",
    "        \n",
    "        for index, row in tqdm(temp_df.iterrows(), total=len(temp_df), desc=\"Validating dataset...\"):\n",
    "            futures.append(executor.submit(_process_file, index, row['filepath']))\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Finishing validation of dataset...\"):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                missing_indices.append(result)\n",
    "    \n",
    "    # Remove missing files\n",
    "    if missing_indices:\n",
    "        temp_df = temp_df.drop(missing_indices)\n",
    "        temp_df.to_csv(LABEL_DATAFRAME)\n",
    "        print(f\"Removed {len(missing_indices)} missing files from dataset\")\n",
    "\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6db11c5c-e908-4bd1-bcc9-49b641b6a29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 14:40:07,781 - INFO - Seed set to 42\n",
      "2025-10-21 14:40:07,784 - INFO - Training mode: finetune\n",
      "2025-10-21 14:40:07,786 - INFO - Config: batch_size=32, epochs=20, lr=1e-05, model=convnextv2_base, img_size=224\n",
      "2025-10-21 14:40:07,981 - INFO - Loaded dataframe from ./compiled/compiled/action_labels.csv with shape (91862, 20)\n",
      "2025-10-21 14:40:08,162 - INFO - Using stratified subset fraction=1; subset size=91862\n",
      "2025-10-21 14:40:08,171 - INFO - Detected 19 labels\n",
      "2025-10-21 14:40:08,509 - INFO - Saved label distribution plot\n",
      "2025-10-21 14:40:11,104 - INFO - Split sizes -> train: 73476, test (used for validation): 18386\n",
      "2025-10-21 14:40:11,115 - INFO - Loader sizes -> train: 73476, test (validation): 18386\n"
     ]
    }
   ],
   "source": [
    "training_mode = TRAINING_MODE\n",
    "if training_mode == 'finetune':\n",
    "    LEARNING_RATE = FINETUNE_LEARNING_RATE\n",
    "    NUM_EPOCHS = FINETUNE_EPOCHS\n",
    "elif training_mode == 'full_retrain':\n",
    "    LEARNING_RATE = RETRAIN_LEARNING_RATE\n",
    "    NUM_EPOCHS = RETRAIN_EPOCHS\n",
    "\n",
    "set_seed(SEED)\n",
    "ensure_output_dir(OUTPUT_DIR)\n",
    "import logging\n",
    "logger = logging.getLogger(\"trainer\")\n",
    "if not logger.handlers:\n",
    "    logger.setLevel(logging.INFO)\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.INFO)\n",
    "    fh = logging.FileHandler(os.path.join(OUTPUT_DIR, 'run.log'))\n",
    "    fh.setLevel(logging.INFO)\n",
    "    fmt = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    ch.setFormatter(fmt)\n",
    "    fh.setFormatter(fmt)\n",
    "    logger.addHandler(ch)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "logger.info(f\"Seed set to {SEED}\")\n",
    "logger.info(f\"Training mode: {training_mode}\")\n",
    "# Resolve effective image size based on selected model\n",
    "effective_img_size = MODEL_CATALOG.get(MODEL_NAME)\n",
    "logger.info(f\"Config: batch_size={BATCH_SIZE}, epochs={NUM_EPOCHS}, lr={LEARNING_RATE}, model={MODEL_NAME}, img_size={effective_img_size}\")\n",
    "\n",
    "df = load_dataframe(LABEL_DATAFRAME)\n",
    "logger.info(f\"Loaded dataframe from {LABEL_DATAFRAME} with shape {df.shape}\")\n",
    "df = build_filepaths(df, DATASET_SRC)\n",
    "# df = validate_dataset(df)\n",
    "\n",
    "# Get label columns before subset selection for stratified sampling\n",
    "label_cols = get_label_columns(df)\n",
    "df = select_subset(df, DATASET_SIZE_PERC, label_cols)\n",
    "logger.info(f\"Using stratified subset fraction={DATASET_SIZE_PERC}; subset size={len(df)}\")\n",
    "# Save label names\n",
    "with open(os.path.join(OUTPUT_DIR, 'labels.json'), 'w') as f:\n",
    "    json.dump(label_cols, f, indent=2)\n",
    "logger.info(f\"Detected {len(label_cols)} labels\")\n",
    "\n",
    "# Plot label distribution\n",
    "plot_label_distribution(df, label_cols, os.path.join(OUTPUT_DIR, 'label_distribution.png'))\n",
    "logger.info(\"Saved label distribution plot\")\n",
    "\n",
    "# Stratified splits\n",
    "df_train, df_test = multilabel_stratified_split(\n",
    "    df, label_cols, TRAIN_SIZE_PERC, TEST_SIZE_PERC, SEED\n",
    ")\n",
    "logger.info(f\"Split sizes -> train: {len(df_train)}, test (used for validation): {len(df_test)}\")\n",
    "\n",
    "train_tfms, val_tfms = make_transforms(effective_img_size)\n",
    "train_ds = MultiLabelImageDataset(df_train, label_cols, train_tfms)\n",
    "test_ds = MultiLabelImageDataset(df_test, label_cols, val_tfms)\n",
    "\n",
    "pin = torch.cuda.is_available()\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=pin,\n",
    "    persistent_workers=(NUM_WORKERS > 0),\n",
    "    prefetch_factor=2 if NUM_WORKERS > 0 else None,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=pin,\n",
    "    persistent_workers=(NUM_WORKERS > 0),\n",
    "    prefetch_factor=2 if NUM_WORKERS > 0 else None,\n",
    ")\n",
    "logger.info(f\"Loader sizes -> train: {len(train_loader.dataset)}, test (validation): {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03195bff-f294-4761-9861-d10152c5784c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision('medium')\n",
    "    except Exception:\n",
    "        pass\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dba4c25-cf91-4aeb-81ae-c052d27bad22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 14:40:54,098 - INFO - Using device: cuda - NVIDIA GeForce RTX 5090\n",
      "2025-10-21 14:40:54,101 - INFO - Model convnextv2_base initialized with 87712275 params\n",
      "2025-10-21 14:40:54,109 - INFO - pos_weight stats -> min: 0.258, max: 4.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuning mode: Frozen 232 parameters\n",
      "Finetuning mode: Trainable 148 parameters\n",
      "Finetuning optimizer: 148 trainable parameters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27195178996444385cda9c2eafbbf81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CUDA: Epoch 1/20:   0%|          | 0/2297 [00:03<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/20 - train_loss: 0.1562 test_loss: 0.1551 AUROC: 0.9642 mAP: 0.8319\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c028febfad3c4518aceaba0d43f8a4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CUDA: Epoch 2/20:   0%|          | 0/2297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02/20 - train_loss: 0.0905 test_loss: 0.1310 AUROC: 0.9772 mAP: 0.8853\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91be7208c384048805e55e5a0684d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CUDA: Epoch 3/20:   0%|          | 0/2297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03/20 - train_loss: 0.0696 test_loss: 0.1177 AUROC: 0.9812 mAP: 0.9022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179552e4e1394e8fa074b2ef1e3d7356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CUDA: Epoch 4/20:   0%|          | 0/2297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04/20 - train_loss: 0.0562 test_loss: 0.1120 AUROC: 0.9826 mAP: 0.9093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731d68d3d5794cc2b4d09f221b0fafa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CUDA: Epoch 5/20:   0%|          | 0/2297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model(num_classes=len(label_cols), training_mode=training_mode).to(device)\n",
    "logger.info(f\"Using device: {device}{' - ' + torch.cuda.get_device_name(0) if device.type == 'cuda' else ''}\")\n",
    "logger.info(f\"Model {MODEL_NAME} initialized with {sum(p.numel() for p in model.parameters())} params\")\n",
    "\n",
    "pos_weight = compute_pos_weight(df_train, label_cols)\n",
    "logger.info(f\"pos_weight stats -> min: {pos_weight.min().item():.3f}, max: {pos_weight.max().item():.3f}\")\n",
    "result = train(model, train_loader, test_loader, device, pos_weight, NUM_EPOCHS, LEARNING_RATE, THRESHOLD, OUTPUT_DIR, training_mode)\n",
    "\n",
    "# Final evaluation on test set (which was used for validation during training)\n",
    "ckpt_path = os.path.join(OUTPUT_DIR, 'best_model.pt')\n",
    "if os.path.exists(ckpt_path):\n",
    "    state = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(state['model_state_dict'])\n",
    "logger.info(\"Loaded best checkpoint for final evaluation\" if os.path.exists(ckpt_path) else \"Evaluating current model\")\n",
    "final_loss, final_auroc, final_mAP = evaluate(model, test_loader, device, THRESHOLD)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'final_metrics.json'), 'w') as f:\n",
    "    json.dump({'final_loss': final_loss, 'final_auroc': float(final_auroc), 'final_mAP': float(final_mAP)}, f, indent=2)\n",
    "logger.info(f\"Final evaluation - loss: {final_loss:.4f} AUROC: {final_auroc:.4f} mAP: {final_mAP:.4f}\")\n",
    "\n",
    "# tiny 0.5 224: Epoch 10/20 - train_loss: 0.0544 test_loss: 0.1484 AUROC: 0.9642 mAP: 0.8402\n",
    "# base 0.5 224: Epoch 05/20 - train_loss: 0.0581 test_loss: 0.1216 AUROC: 0.9756 mAP: 0.8828\n",
    "# tiny 1.0 224: Epoch 07/20 - train_loss: 0.0606 test_loss: 0.1265 AUROC: 0.9758 mAP: 0.8806\n",
    "# base 1.0 224: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d96fb7-650a-439d-9756-62deb1c30268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
